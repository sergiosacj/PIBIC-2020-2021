‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ superscription ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
iter....: current iteration
f(x*)...: objective function avaluated at x(iter)
‖∇f(x)‖.: gradient norm used to calculate x(iter), so x in ‖∇f(x)‖ is equal to x(iter-1)
alpha...: step calculated by backtrack line search
‖d‖.....: search direction norm
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
__________________________________________________________________________________________
iter   f(x*)            ‖∇f(x)‖         sigma          
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
1      9.887640e+01     4.322063e-12    0.000000e+00   
2      9.864087e-02     6.765020e-11    0.000000e+00   
3      8.822158e-05     1.256074e-13    0.000000e+00   
4      8.030371e-12     1.324914e-14    0.000000e+00   
5      -1.442396e-23    0.000000e+00    0.000000e+00   
6      1.244921e-26     4.984938e-12    0.000000e+00   


‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ summary statistics ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
Total iterations......: 7
AF....................: 12
AG....................: 13
AH....................: 6
f(x*).................: 0.000000e+00
‖∇f(x)‖...............: 0.000000e+00
sigma.................: 0.000000e+00
stop..................: Converged
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾

