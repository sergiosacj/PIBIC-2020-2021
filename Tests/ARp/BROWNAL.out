‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ superscription ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
iter....: current iteration
f(x*)...: objective function avaluated at x(iter)
‖∇f(x)‖.: gradient norm used to calculate x(iter), so x in ‖∇f(x)‖ is equal to x(iter-1)
alpha...: step calculated by backtrack line search
‖d‖.....: search direction norm
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
__________________________________________________________________________________________
iter   f(x*)            ‖∇f(x)‖         sigma          
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
1      -1.040179e+01    7.788968e-03    0.000000e+00   
2      3.402396e-01     6.651750e-06    1.000000e-07   
3      8.059701e-01     4.151995e-06    1.000000e-06   
4      8.700094e-01     2.830357e-06    1.000000e-05   
5      7.061296e-01     2.336619e-02    0.000000e+00   
6      1.062613e-01     3.026631e-10    0.000000e+00   
7      3.484916e-03     1.161811e-11    0.000000e+00   
8      -6.024004e-06    3.717739e-12    0.000000e+00   
9      -6.782446e-10    4.346429e-14    0.000000e+00   
10     1.126224e-14     3.267030e-09    0.000000e+00   
11     1.126258e-14     3.617118e-09    0.000000e+00   


‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ summary statistics ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
Total iterations......: 12
AF....................: 22
AG....................: 12
AH....................: 0
f(x*).................: 1.126258e-14
‖∇f(x)‖...............: 3.617118e-09
sigma.................: 0.000000e+00
stop..................: 0
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾

