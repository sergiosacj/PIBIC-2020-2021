‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ superscription ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
iter....: current iteration
f(x*)...: objective function avaluated at x(iter)
‖∇f(x)‖.: gradient norm used to calculate x(iter), so x in ‖∇f(x)‖ is equal to x(iter-1)
alpha...: step calculated by backtrack line search
‖d‖.....: search direction norm
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
__________________________________________________________________________________________
iter   f(x*)            ‖∇f(x)‖         sigma          
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
1      -6.733759e+11    1.881256e+06    0.000000e+00   
2      -6.782331e+10    5.946832e+05    1.000000e-07   
3      -7.214340e+09    1.913677e+05    1.000000e-06   
4      -6.613519e+08    5.554063e+04    1.000000e-05   
5      -4.779015e+07    1.304615e+04    1.000000e-04   
6      -2.165856e+06    1.608818e+03    1.000000e-03   
7      -3.229282e+04    4.917225e+00    1.000000e-02   
8      -4.868271e+02    9.129971e-06    1.000000e-01   
9      -2.795738e+01    3.278070e-06    1.000000e+00   
10     3.283500e+01     3.683667e-10    0.000000e+00   


‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ summary statistics ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
Total iterations......: 11
AF....................: 11
AG....................: 11
AH....................: 0
f(x*).................: 3.283500e+01
‖∇f(x)‖...............: 3.683667e-10
sigma.................: 0.000000e+00
stop..................: 0
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾

