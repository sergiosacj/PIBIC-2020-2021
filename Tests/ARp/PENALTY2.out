‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ superscription ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
iter....: current iteration
f(x*)...: objective function avaluated at x(iter)
‖∇f(x)‖.: gradient norm used to calculate x(iter), so x in ‖∇f(x)‖ is equal to x(iter-1)
alpha...: step calculated by backtrack line search
‖d‖.....: search direction norm
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
__________________________________________________________________________________________
iter   f(x*)            ‖∇f(x)‖         sigma          
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
1      4.711629e+13     1.415132e-09    0.000000e+00   
2      4.711628e+13     1.616312e-09    0.000000e+00   
3      4.711628e+13     1.264254e-09    0.000000e+00   
4      4.711628e+13     3.738162e-10    0.000000e+00   
5      4.711628e+13     3.477294e-11    0.000000e+00   
6      4.711628e+13     4.264738e-11    0.000000e+00   
7      4.711628e+13     1.096057e-10    0.000000e+00   
8      4.711628e+13     6.003551e-10    0.000000e+00   
9      4.711628e+13     4.400836e-10    0.000000e+00   
10     4.711628e+13     2.711816e-10    0.000000e+00   
11     4.711628e+13     1.475497e-11    0.000000e+00   


‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾ summary statistics ‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾
Total iterations......: 12
AF....................: 13
AG....................: 12
AH....................: 0
f(x*).................: 4.711628e+13
‖∇f(x)‖...............: 1.475497e-11
sigma.................: 0.000000e+00
stop..................: 0
‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾‾

